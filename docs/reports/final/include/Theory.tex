% CREATED BY DAVID FRISK, 2016
\chapter{Theory} \label{chapter:theory}
Our system could be seen as an extension to \emph{$\lambda$-calculus} with dependent types and definitions. In order for the reader to understand better the idea behind the choice of the syntax and semantics of our language, we first illustrate some subtleties of the system which suggest common pitfalls one should avoid in the implementation.
\section{Subtleties} \label{theory:subtleties}
We present the subtleties by giving examples as the follows. 
\begin{example}\label{theory:example-1}
  Suppose we have declarations
  \begin{align*}
    x &: A \\
    y &: A \\
    b &: A \to A \to A \\
    u &: (A \to A \to A) \to (A \to A \to A) \\
    a &: (A \to A) \to (A \to A) \\
    z &: A \to A \to A
  \end{align*}
  Then the term below is well typed.
  \begin{equation}\label{eq-cap-var:1}
    (\lambda u \; . \; u \; (u \; b)) (\lambda z \; y \; x \; . \; a \; (z \; x) \; y)
  \end{equation}
  If we do the reduction on (\ref{eq-cap-var:1}) naively, we get
  \begin{align}
    (\lambda u \; . \; u \; (u \; b)) (\lambda z \; y \; x \; . \; a \; (z \; x) \; y) & \implies \nonumber \\
    (\lambda z \; y \; x \; . \; a \; (z \; x) \; y) ((\lambda z \; y \; x \; . \; a \; (z \; x) \; y) \; b) & \implies \nonumber \\
    (\lambda z \; y \; x \; . \; a \; (z \; x) \; y) (\lambda y \; x \; . \; a \; (b \; x) \; y) & \implies \nonumber \\
    \lambda y \; x \; . \; a \; ((\lambda y \; x \; . \; a \; (b \; x) \; y)\; x) \; y \label{eq-cap-var:2}
  \end{align}
  At this point, we have a capture of variables problem. (\ref{eq-cap-var:2}) should be the same as
  \[ \lambda y \; x \; . \; a \; ((\lambda y \; x' \; . \; a \; (b \; x') \; y)\; x) \; y \]
  which reduces to
  \[ \lambda y \; x \; . \; a \; (\lambda x' \; . \; a \; (b \; x') \; x) \; y \]
  But if we do a naive reduction in (\ref{eq-cap-var:2}) without renaming, we get 
  \[ \lambda y \; x \; . \; a \; (\lambda x \; . \; a \; (b \; x) \; x) \; y \]
  which is not correct. This example comes from the PhD thesis of L.S. van Benthem Jutting in 1977\cite{van1994checking} when he was working on AUTOMATH. It was conjectured that if one starts with a term where each bound variable is only declared once, then there will not be any capture of variables by reduction. This example shows that this is not the case and manifests an unusual case of the problem known as the capture of names by preforming reductions in $\lambda$-calculus.
\end{example}

\begin{example}\label{theory:example-2}
  In non-dependent type languages like Java and Haskell, one can interpret the definition by function application. For example, one can interpret the definition of $i1$ in following piece of java code
  \begin{lstlisting}[language=java]
    int i1 = 0;
    int i2 = i1 + 1;
  \end{lstlisting}
  by $i2 = (\lambda (x:int).x + 1)0$, and the definition of $x$ in the following Haskell code
  \begin{lstlisting}
    let x = 0 in x + x
  \end{lstlisting}
  by $(\lambda x.x + x)\,0$. This, however, is not always possible in a dependent type language. As an example, suppose we have
  \[ a : A, \;\;\; P : A \to U, \;\;\; f : P \, a \to P \, a \]
  then program
  \begin{lstlisting}
    let x : A = a, y : P x in f y
  \end{lstlisting}
  cannot be rewritten to an application $(\lambda (x : A) (y : P\,x) . f\,y)\,a$ because the former part of the formula, $\lambda (x : A) (y : P\,x) . f\,y$, is not well-typed: the type of y is $P\,x$ whereas the type of the argument to $f$ should be $P\,a$. 
This example shows that definitions in dependent type theory cannot be reduced to \emph{$\lambda$-calculus}.
\end{example}

\begin{example}\label{theory:example-3}
  Consider the formula
  \[ \lambda (x : \textbf{Nat}) (y : \textbf{Nat} = x) (x : \textbf{Bool}).y\]
  where \textbf{Nat} is the type of natural numbers and \textbf{Bool} is the type of Boolean. In this formula, the first declaration of $x$ is shadowed by the second one. If we do not treat the shadowing of names properly, we may incorrectly conclude that we have a context where (1) the definition of $y$ is $x$, (2) the type of $y$ is \textbf{Nat}, whereas (3) the type of $x$ is \textbf{Bool}. This example shows that improper use and treatment of name shadowing leads to inconsistency.
\end{example}

\section{Principles}
Example \ref{theory:example-1} and \ref{theory:example-3} provide us with insights into two common pitfalls one should avoid in the implementation: (1) capture of names during reduction and (2) improper treatment of name shadowing. As a result, we put forward two principles as a measure to ward off these two traps.
\begin{principle}\label{theory:principle-1}
  Use closure to postpone reduction.
\end{principle}
\begin{principle}\label{theory:principle-2}
  Forbid the practice of name shadowing.
\end{principle}
Principle \ref{theory:principle-1} comes as a measure to tackle the problem of capture of names. Here, a closure is a computation structure consists of a function ($\lambda$-abstraction) and an \emph{environment} which binds free variables of the function to terms that waits to be substituted. The idea of postponed reduction is that for a function application, the actual substitution is not performed until the body  of the function is clear of abstractions. For example, consider an application ($f\;0$) on a function $f$ defined as follows.
\[ f = \lambda x \lambda y.x + y \]
By normal $\beta$-reduction, the result would be $\lambda y.0 + y$. But if we reduce it by using closure, the result would instead be $\langle{\lambda y. x+y, (x = 0)}\rangle$: a closure formed by a function ($\lambda y.x+y$) and an environment $(x = 0)$. We do not perform substitution at this stage because the body of $f$ is still a $\lambda$-abstraction. If we apply the result to another argument, say 1, because the body of the function is now free of abstractions, substitutions for both $x$ and $y$ will be performed and the result would be $0 + 1 = 1$. The reason why the problem of variable capture can be avoid by using closure is that by deferring substitution, the structure of the function body is well preserved and by the time the substitution really happens, only the variables that are originally bound in the body will be substituted by their binding terms. We will talk more about closure later when we introduce the semantics of our language in section \ref{theory:semantic}. An example of using closure to evaluate the expression \ref{eq-cap-var:1} could be found in appendix \ref{apdix:closure}.

Principle \ref{theory:principle-2} comes as a simple strategy to avoid the pitfall revealed by example \ref{theory:example-3}. It means during the type checking process, each declaration, including declaration of bound variable in $\lambda$-abstraction, is checked with the top level context to ensure no name collision occurs. Another approach to the name shadowing problem is called \emph{namespaced De Bruijn indices}\footnote{for a detailed introduction, please visit  \href{https://www.haskellforall.com/2021/08/namespaced-de-bruijn-indices.HTML}{this website}.}, which is a technique adopted by Agda currently\footnote{tested with version 2.6.2.}. The idea is to decorate the variables declared with the same name with integer indices to tell them apart from each other. However, some experience with Agda shows that the context information inferred by Agda using indexed variables can be confusing at times. As an example, consider the following Agda program.
\begin{Verbatim}[fontsize=\small]
1  module test where
2
3  open import Data.Nat
4  open import Data.Bool
5
6  test : N → Bool → N 
7  test = λ (x : N) →
8    let y : N 
9        y = x
10   in λ (x : Bool) → {!!}
\end{Verbatim}
We ignore non-essential details but only illustrate points where relevant.
\begin{itemize}
\item Line 6-10 is a definition of constant \emph{test} which is a function that given a natural number and a Boolean, returns a natural number.
\item Two variables of the same name $x$ are declared, one in the outer scope at line 7, another in the inner scope at line 10.
\item The $x$ in the outer scope has the type natural number, whereas the $x$ in the inner scope has the type Boolean.
\item In the placeholder denoted by the text \texttt{\{!!\}}, using the interactive proof assistant feature provided by Agda, we ask for the context information.
\end{itemize}
The context information inferred by Agda is:
\begin{Verbatim}[fontsize=\small]
Goal: N
————————————————————————————————————————————————————————————
y      : N 
y      = x_1
x      : Bool
x = x_1 : N   (not in scope)
\end{Verbatim}
What Agda means in this message is that:
\begin{itemize}
\item $y$ is of type $N$ and is defined to be the $x$ in the outer scope, thus having the index $1$.
\item $x$ in the inner scope is of type $Bool$ with no definition.
\item $x$ in the outer scope (indicated by the phrase ``not in scope'') is of type $N$ and is defined to be $x_1$.
\end{itemize}
The message shows that Agda is able to keep track of variables declared with the same name correctly by labeling them with indices. However, the way it presents the context information can cause confusion for users who are not familiar with this feature: by reading the text \texttt{y = $x_1$}, \texttt{x:Bool} and \texttt{x = $x_1$}, one may wonder how it is possible for both $y$ and $x$ to be equal with $x_1$ since they have different types. Another inefficiency with this approach is that the end user cannot refer to the $x$ in the outer scope by the name $x_1$ because $x_1$ is used as an internal identifier and there is no variable in the source file having name $x_1$. Such an attempt will be rejected by Agda with an error message meaning that ``variable not in scope''. In summary, we consider allowing the feature of name shadowing causes confusion in the context information and introduces ambiguity over the usage of names (e.g., for name $x_1$, should it be taken as an internal identifier or a common name?). For this reason, we simply forbid the shadowing of names in our language.

\section{Syntax of the Language}\label{theory:sec:syntax}
There are two kinds of syntax regarding the language: (1) The concrete syntax that describes the grammar used in a source file, and (2) the abstract syntax translated from the concrete syntax for clarity and better presentation. What we are going to describe below is the abstract syntax, for the concrete syntax see appendix \ref{apdix:concrete-syntax-basic}. 

Expression in our language is defined as follows:
\begin{definition}[Expression]\label{theory:def:exp}
  \leavevmode \vspace{-\baselineskip}
  \begin{enumerate}[(i)]
    \item $U$ is an expression, which represents a universe of small types. $U$ is an element of itself, i.e., $U \in U$.
    \item A special group of terms, denoted as $\mathcal{K}$, are expressions and defined inductively by
      \begin{enumerate}
      \item variables, e.g., $x,y,z$;
      \item terms of the form $K\,M$, where $K \in \mathcal{K}$ and $M$ is an expression. 
      \end{enumerate}
    \item Given two expressions $A, M$ and a variable $x$, a term of the form
      \[ [x : A] M \]
      is an expression, which is used to represent
      \begin{itemize}
        \item \textbf{$\lambda$-abstraction}: $\lambda_{x : A}M$ - a function that given an argument $x$ of type $A$, returns a term $M$ which may depend on $x$;
      \end{itemize}
      \begin{itemize}
        \item \textbf{Dependent Product}: $\Pi_{x : A}M$ - the type of function that given an argument $x$ of type $A$, returns a term of type $M$ which may depend on $x$. When $M$ does not depend on $x$, we can ignore $x$ and rewrite it as $\Pi_{\_:A}M$. This is essentially the same as the type of function $A \to M$.
      \end{itemize}
    \item Given three expressions $A,B,M$ and a variable $x$, a term of the form
      \[ [x : A = B] M \]
      is an expression, which is used to represent a let clause:
      \begin{itemize}
        \item let $x : A = B$ in $M$.
      \end{itemize}
  \end{enumerate}
\end{definition}

Declaration in our language is defined as follows:
\begin{definition}[Declaration]\label{theory:def:decl}
  \leavevmode \vspace{-\baselineskip}
  \begin{enumerate}[(i)]
  \item A term of the form $x : A$ is a declaration where $x$ is a variable and $A$ is a type. It declares a variable $x$ of type $A$.
  \item A definition $x : A = B$ is a declaration where $x$ is a variable and $A,B$ are expressions. It declares of a variable $x$ of type $A$ and defined as $B$.
  \end{enumerate}
\end{definition}

A program of our language consists of a list of declarations. The name of a declaration must not collide with any name of the existing declarations and a variable must be declared before it is used. A summary of the syntax could be found in table \ref{theory:tab:syntax}, where $A,M,K$ represent expressions; $D$ represents definitions; $Decl$ represents declarations and $P$ represents programs.
\begin{table}[h]
  \centering
  \begin{tabular}{l l l}
    $A,M$ & ::= & $U \mid K \mid [x : A]M \mid D\,M$ \\
    $K$ & ::= & $x \mid K\,M$ \\
    $D$ & ::= & $x : A = M$ \\
    $Decl$ & ::= & $x : A \mid D$ \\
    $P$ & ::= & $[Decl]$
  \end{tabular}
  \caption{Syntax of the Language}
  \label{theory:tab:syntax}
\end{table}

The syntax of our language is a subset of Mini-TT\cite{coquand2009simple}. We use the same syntax for both dependent product and $\lambda$-abstraction as an effort to maintain simplicity. This practice causes ambiguity only when an expression in the form $[x : A] M$ is viewed in isolation: it can be seen both as a dependent type and a function abstraction. This ambiguity, however, does not cause problem in practice because the meaning of a term could be deduced from the context and our type checking algorithm ensures the consistency of its usage.

The classification of a subset of expressions denoted as $\mathcal{K}$ indicates that expressions in the language conform to the $\beta$-normal form, i.e., expressions of the form $U\,M$, $([x:A]M)\,E$ are considered illegal. The former is easy to understand as $U$ is not a function; the latter is subject to $\beta$-reduction which is prohibitive in the language. We use this practice as a measure to keep the brevity of the type checking algorithm.

\section{Operational Semantics}\label{theory:semantic}
Given a well-formed expression, we describe in this section how it is evaluated in the semantics of our language. An expression is evaluated to a \emph{quasi-expression} or \emph{q-expression} in an \emph{environment}, a stack structure in one of the following forms: 
\begin{definition}[Environment]
  \leavevmode \vspace{-\baselineskip}
  \begin{enumerate}[(i)]
  \item $()$, an empty environment;
  \item $(\rho_1, x = v)$, an environment extended from a smaller one $\rho_1$ by binding a variable $x$ to a q-expression $v$;
  \item $(\rho_1, D)$, an environment extended from a smaller one $\rho_1$ by a definition.
  \end{enumerate}
\end{definition}

A \emph{q-expression} is the intermediate form of an expression under evaluation. It can be transformed to a ``normal'' expression by a procedure called ``readBack'' which will be introduced later in section \ref{theory:head-red}. Sometimes we also call q-expressions as \emph{values}.
\begin{definition}[q-expression]\label{theory:def:q-exp}
  \leavevmode \vspace{-\baselineskip}
  \begin{enumerate}[(i)]
    \item $U$ is a q-expression, it is the result of the expression $U$ under evaluation.
    \item A variable $x$ is a q-expression, it represents a primitive without definition. 
    \item A closure $\langle [x : A] M, \rho \rangle$ is a q-expression, it is the result of a function $[x:A]M$ under evaluation in the environment $\rho$.
    \item Given two q-expressions $k,v$, $k$ is not a closure, a term of the form $k\,v$ is a q-expression, which represents an application that cannot be reduced further.
  \end{enumerate}
\end{definition}

The form of q-expression can be summarized in table \ref{theory:tab:q-expression}.
\begin{table}[h]
  \centering
  \begin{tabular}{l l l l}
    $k$ & ::= & $x \mid k\,v$ \\
    $v$ & ::= & $U \mid k \mid \langle [x:A]M,\rho \rangle$
  \end{tabular}
  \caption{Form of Q-expression}
  \label{theory:tab:q-expression}
\end{table}

The evaluation function, given in table \ref{theory:tab:semantics}, is denoted by formulas of the form $M_\rho = q$, meaning that the expression $M$ evaluates to $q$ in the environment $\rho$.
\begin{table}[h]
  \centering
  \begin{tabular}{l l l}
    $U_\rho$ & = & $U$ \\
    $x_\rho$ & = & $\rho(x)$ \\
    $(K\,N)_\rho$ & = & $app(K_\rho, N_\rho)$ \\
    $([x : A]B)_\rho$ & = & $\langle[x : A]\,B, \rho\rangle$ \\
    $(D\,M)_\rho$ & = & $M_{(\rho,D)}$ 
  \end{tabular}
  \caption{Semantics of the Language}
  \label{theory:tab:semantics}
\end{table}

Two auxiliary functions are used in the evaluation with their definitions given in given in table \ref{theory:tab:lookup}, \ref{theory:tab:app} respectively.
\begin{itemize}
\item $\rho(x)$: find the binding q-expression of the variable $x$ in the environment $\rho$.
\item $app(k, v)$: apply function $k$ to $v$. 
\end{itemize}

\begin{table}[h]
  \centering
  \begin{tabular}{r l l}
    $()(x)$ & = & $x$ \\
    $(\rho', x' = v)(x)$ & = & if $x' == x$ then $v$ else $\rho'(x)$ \\
    $(\rho', x' : A = B)(x)$ & = & if $x' == x$ then $B_{\rho'}$ else $\rho'(x)$
  \end{tabular}
  \caption{Function - $\rho(x)$}
  \label{theory:tab:lookup}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{r l l}
    $app(\langle [x : A]M, \rho \rangle, v)$ & = & $M_{(\rho, x = v)}$\\
    $app(k,v)$ & = & $k\,v$
  \end{tabular}
  \caption{Function - $app(k, v)$}
  \label{theory:tab:app}
\end{table}

Some readers may have noticed that the real difference between expression and q-expression is closure. Closure is an important concept in functional programming and was first conceived by P. J. Landin in his paper \emph{The Mechanical Evaluation of Expressions}\cite{landin1964mechanical}. There, the author described closure as ``$\dots$comprising the $\lambda$-expression and the environment relative to which it was evaluated$\dots$'' which specified the structure of closure we adhere to in our own implementation. Closure is introduced to meet the need of passing functions as values around during evaluation and entails the introduction of q-expression as a parallel but distinct concept from expression. One major benefit brought by using closure is the ability to defer computation.

The meaning of deferred computation comes into twofold: First, evaluation of the reducible expressions in the function body is deferred, as signified by the rule about evaluation of function in table \ref{theory:tab:semantics} where the function body is left intact; Second, the substitution process in $\beta$-reduction is deferred as indicated by the definition of function \emph{app} in table \ref{theory:tab:app}. For an application of function $[x:A]M$ to an argument $v$, the substitution will not happen until $M$ is clear of abstraction. The ability to defer computation is crucial for the definition mechanism as it makes possible for saving computations during the evaluation process.

\section{Type Checking Algorithm}\label{theory:sec:check}
The aim of the type checking algorithm is to ensure a program of our language is well-typed. Basically, for a declaration in the form $x : A$, it checks that $A$ is a valid type, namely $A \in U$; for a declaration in the form $x : A = B$, it checks that (1) $A$ is a valid type and (2) $B$ is a well-typed expression and has type $A$. A program is said to be well-typed when each of its declaration is well-typed.

Note that the type checking algorithm does not concern any syntactic or semantic error related with names, such as duplicated declaration of names or use of undeclared names. Syntactic error is checked by the lexer and parser where a source file is parsed into a concrete syntax tree. Semantic error with regard to the use of names are checked when the concrete syntax tree is translated to an abstract syntax tree in a procedure called \emph{translation}. It is the abstract syntax tree on which the type checking algorithm is applied.

There are three forms of judgments:
\begin{table}[h]
  \centering
  \begin{tabular}{l l l}
    checkD & $\Gamma \vdash_s d \Rightarrow \Gamma'$ & $d$ is a valid declaration and extends $\Gamma$ to $\Gamma'$ \\
    checkT & $\Gamma \vdash_s M \Leftarrow t$ & $M$ is a valid expression given type $t$. \\
    checkI & $\Gamma \vdash_s K \Rightarrow t$ & $K$ is a valid expression and its type is inferred to be $t$.
  \end{tabular}
  \caption{Type Checking Judgments}
  \label{theory:tab:judgments}
\end{table}

The lower case letter $t$ represents a q-expression, meaning that the type inferred by \emph{checkI} or given as an input in \emph{checkT} must be an evaluated expression. $\Gamma$ represents the \emph{type checking context} which is a stack structure keeping track of the types and definitions of the variables. $s$ represents a \emph{lock strategy}. 
\begin{definition}[Type Checking Context]
  A type checking context $\Gamma$ has one of the three forms.
  \begin{enumerate}[(i)]
  \item $()$: $\Gamma$ is an empty context.
  \item $(\Gamma_1, x : A)$: $\Gamma$ is a context extended from $\Gamma_1$ by a declaration $x:A$.
  \item $(\Gamma_1, x : A = B)$: $\Gamma$ is a context extended from $\Gamma_1$ by a definition $x:A=B$.
  \end{enumerate}
\end{definition}
In the type checking algorithm, $\Gamma$ serves two main purposes: (1) provides the types of variables declared inside of the context and (2) provides the environment customized by a lock strategy for evaluation.

Lock strategy is introduced as a part of our definition mechanism to provide the locking/unlocking functionality on constants. A constant is \emph{locked} when its definition is temporarily erased and \emph{unlocked} if restored. A locked constant is in effect a primitive variable that cannot be reduced further. Since environment is the place where variables are mapped to their definitions or values (q-expressions) during evaluation, we can achieve the effect of locking/unlocking constants by removing/restoring their definitions from/to the environment. This suggests a procedure to transform a type checking context into an environment with the definitions of constants being erased or restored. We introduce a function \emph{getEnv} for this purpose and denote it as $\varrho$ in the following discussion. If we consider the symbol of $s$ in table \ref{theory:tab:judgments} being a list of locked variables, the function \emph{getEnv} could be defined as in table \ref{theory:tab:getEnv}.

\begin{table}[h] 
  \centering
  \begin{tabular}{l l l}
    $\varrho(s, ())$ & = & () \\
    $\varrho(s, (\Gamma, x : A))$ & = & $\varrho(s, \Gamma)$ \\
    $\varrho(s, (\Gamma, x : A = B))$ & = & let $\rho = \varrho(s, \Gamma)$ in if $x \in s$ then $\rho$ else $(\rho, x : A = B)$
  \end{tabular}
  \caption{Function: getEnv}
  \label{theory:tab:getEnv}
\end{table}

Given a type checking context $\Gamma$ and a lock strategy $s$, we can get the evaluated form of the type of a variable $x$ by function \emph{getType}. We denote this function as $\Gamma(s,x)$ and give its definition in table \ref{theory:tab:getType}.
\begin{table}[h]
  \centering
  \begin{tabular}{r l l}
    $()(s,x)$ & = & \emph{error} \\
    $(\Gamma', x' : A)(s, x)$ & = & if $x' == x$ then $A_{\varrho(s, \Gamma')}$ else $\Gamma'(s,x)$ \\
    $(\Gamma', x' : A = B)(s, x)$ & = & if $x' == x$ then $A_{\varrho(s, \Gamma')}$ else $\Gamma'(s,x)$
  \end{tabular}
  \caption{Function - getType}
  \label{theory:tab:getType}
\end{table}

The first case of the function means that if we try to get the type of a variable that does not exist in the type checking context, an exception is raised. In our implementation, during the \emph{translation} process we mentioned earlier, we make sure that each variable is properly declared with a type and the name of the variable does not clash with the existing ones. By doing so, we ensure that the error condition will never actually happen during the type checking process.

In the type checking process, the convertibility of terms is expressed by a predicate \emph{checkConvert} which given a list of names, decides whether two q-expressions are convertible. We use the notation $q_1 \sim_{ns} q_2$ to express that $q_1$ and $q_2$ are convertible. The list of names $ns$ is used to ensure that names newly introduced in the convertibility checking process do not collide with the names already existed in the underlying type checking context. The definition of \emph{checkConvert} is given in table \ref{theory:tab:check-convert}. Note that the rules presented here only checks $\beta$-convertibility, for $\eta$-convertibility please refer to appendix \ref{apdix:eta}. 

\begin{table}[h]
  \centering
  \begin{tabular}{l p{8cm}}
    $U \sim_{ns} U$ & - \\
    $x \sim_{ns} x$ & - \\
    $k_1\,v_1 \sim_{ns} k_2\,v_2$ & if $k_1 \sim_{ns} k_2$ and $v_1 \sim_{ns} v_2$ \\
    $\langle [x:A]M,\rho \rangle \sim_{ns} \langle [x':A']M',\rho' \rangle$ & check that $A_\rho \sim_{ns} A'_{\rho'}$, let $y = \nu(ns, x)$ \newline check that $M_{(\rho, x = y)} \sim_{y:ns} M'_{(\rho', x' = y)}$
  \end{tabular}
  \caption{Predicate - CheckConvert}
  \label{theory:tab:check-convert}
\end{table}

A new function \emph{freshVar}, denoted as $\nu$, is used to generate a new variable that does not collide with the existing ones from $ns$. Another function \emph{namesCtx}, denoted as $\tau(\Gamma)$, is used to get the names of declarations plus the names of definitions in the let clauses in a context $\Gamma$. We use this function to provide the list of names used by \emph{checkConvert}.

\subsection{checkD}\label{theory:subsec:checkD}
\begin{align}
  &\begin{prooftree}\label{theory:checkD:decl}
    \hypo{\Gamma \vdash_s A \Leftarrow U}
    \infer1{\Gamma \vdash_s x:A \Rightarrow (\Gamma, x:A)}
  \end{prooftree} \\
  \nonumber \\
  &\begin{prooftree}\label{theory:checkD:def}
    \hypo{\Gamma \vdash_s A \Leftarrow U}
    \hypo{\Gamma \vdash_s B \Leftarrow A_{\varrho(s,\Gamma)}}
    \infer2{\Gamma \vdash_s x:A=B \Rightarrow (\Gamma, x:A=B)}
  \end{prooftree}
\end{align}

\subsection{checkT}\label{theory:subsec:checkT}
\begin{align}
  &\begin{prooftree}\label{theory:checkT:u}
    \infer0{\Gamma \vdash_s U \Leftarrow U}
  \end{prooftree} \\
  \nonumber \\
  &\begin{prooftree}\label{theory:checkT:x}
    \hypo{\Gamma(s,x) \sim_{\tau(\Gamma)} t}
    \infer1{\Gamma \vdash_s x \Leftarrow t}
  \end{prooftree}\\
  \nonumber \\
  &\begin{prooftree}\label{theory:checkT:app}
    \hypo{\Gamma \vdash_s K \, N \Rightarrow t'}
    \hypo{t' \sim_{\tau(\Gamma)} t}
    \infer2{\Gamma \vdash_s K \, N \Leftarrow t}
  \end{prooftree} \\
  \nonumber \\
  &\begin{prooftree}\label{theory:checkT:abs}
    \hypo{\Gamma \vdash_s A \Leftarrow U}
    \hypo{(\Gamma, x:A) \vdash_s B \Leftarrow U}
    \infer2{\Gamma \vdash_s [x : A]B \Leftarrow U}
  \end{prooftree}\\
  \nonumber \\
  &\begin{prooftree}\label{theory:checkT:clos}
    \hypo{\Gamma \vdash_s A \Leftarrow U}
    \hypo{A_{\varrho(s,\Gamma)} \sim_{\tau(\Gamma)} A'_{\rho'}}
    \hypo{(\Gamma, x : A) \vdash_s B \Leftarrow B'_{(\rho', x'=x)}}
    \infer3{\Gamma \vdash_s [x : A] \, B \Leftarrow \langle [x' : A'] B',\rho' \rangle}
  \end{prooftree} \\
  \nonumber \\
  &\begin{prooftree}\label{theory:checkT:let}
    \hypo{\Gamma \vdash_s A \Leftarrow U}
    \hypo{\Gamma \vdash_s B \Leftarrow A_{\varrho(s,\Gamma)}}
    \hypo{(\Gamma, x:A=B) \vdash_s M \Leftarrow t}
    \infer3{\Gamma \vdash_s [x : A = B]\,M \Leftarrow t}
  \end{prooftree}
\end{align}
Note that the inference rules \ref{theory:checkT:abs} and \ref{theory:checkT:clos} differentiate between the use of an abstraction $[x:A] B$ as a dependent product or as a function. When used as a dependent product, its type is $U$; otherwise, its type is a closure.

\subsection{checkI}\label{theory:subsec:checkI}
\begin{align}
  &\begin{prooftree}\label{theory:checkI:x}
    \infer0{\Gamma \vdash_s x \Rightarrow \Gamma(s,x)}
  \end{prooftree} \\
  \nonumber \\
  &\begin{prooftree}\label{theory:checkI:app}
    \hypo{\Gamma \vdash_s K \Rightarrow \langle [x : A] B,\rho \rangle}
    \hypo{\Gamma \vdash_s N \Leftarrow A_\rho}
    \infer2{\Gamma \vdash_s K\,N \Rightarrow B_{(\rho, x = n)}}
  \end{prooftree}\left(\begin{array}{l}
                         n = N_{\varrho(s, \Gamma)}
                       \end{array}\right)
\end{align}

\section{Definition Mechanism}\label{theory:sec:definition}
The motivation to build a definition mechanism is to study how to do type checking in the presence of definitions in dependent type theory. In any typed language, one basic problem a type checker should be able to solve is given an expression $E$ and a type $A$, decide whether $E$ is of type $A$. Usually this involves getting the type of $E$, say $T$, by means of computation regarding the composition of $E$ and decide whether $T$ and $A$ are convertible. Difficulty arises in dependent type theory because (1) a type may contain \textbf{any} expression which could entail large amount of computation, and (2) the use of definition opens up the possibility to denote arbitrary complex computation by a single constant. For a type checker of dependent type theory to be efficient, the amount of computation it performed in the convertibility checking should not exceed too much what are ``just enough'' to establish the equivalence of the checked terms. The problem is that there is no standard way to calculate the minimum number of reductions needed because it depends on the semantics, namely the language designer's perception of computation, of the language.

For example, consider again the two formulae $(1 + 1)^{10}$ and $2^{(5+5)}$. To check the convertibility of these two terms, if we adopt the common arithmetic definition about the integer multiplication and exponentiation, and determine that any expression should be evaluated to the normal form (no redex exists), a type checker loyal to our conception of computation will reduce both terms to 1024. However, if we change our mind and see exponentiation as a primitive with no definition, then the same type checker with our updated conception will only reduce both terms to $2^{10}$.

Our definition mechanism is an attempt to improve the performance of convertibility checking by setting limit on constants. That is, a constant acts as a unit on which computation could be locked or charged. More advanced computation control technique with finer granularity is desired, as can be shown by the following example which is a variant of the example above.

Consider these two formulae $2 * 2^9$ and $2^{10}$. In this case, locking the definition of exponentiation will not work. One solution for this problem is to recognize and utilize the property about exponentiation $2^m * 2^n = 2^{(m+n)}$. Another way is to reduce $2^{10}$ to $2 * 2^9$ using the definition of exponentiation only once. The former suggests a mechanism to establish properties about data types and constants and use these properties in the following computation, a technique that has been adopted by Haskell and proof-assistant systems like Agda; the latter indicates a dynamic change of the evaluation strategy in the process of computation, a hint for more advanced intelligence for the program. Although in this work we didn't go further towards either of the two directions, we do studied and implemented an function called ``linear head reduction'' which could limit reductions performed on expressions each time.

\subsection{Problem of Finding the Minimum Set of Constants}\label{theory:find-minimum}
One application of our definition mechanism is that given a valid context, find the minimum set of constants unfolded such that a new constant could be type checked. More formally, the problem could be formulated as:
\begin{problem}
  $G$ is a valid context and the set of constants from $G$ is $C$. $x$ is a new constant with definition $x:A=B$. Find one minimum set $C_0 \subseteq C$ such that for an arbitrary set $C' \subseteq C$
  \[ G \vdash_{s(C')} x:A=B \Rightarrow (G, x:A=B) \quad \emph{iff} \quad C_0 \subseteq C' \]
  where $s(C')$ is the list of constants to be locked during the type checking process from $C \setminus C'$.
\end{problem}

When $x$ is invalid, the problem is uninteresting because $C_0$ does not exist. When $x$ is valid, we assume the existence and uniqueness of $C_0$ and present below an approximation algorithm to find $C_0$. Notice that according to the rule \ref{theory:checkD:def}, checking $x$ valid entails checking $A \in U$ and $B \in A_{\varrho(s,G)}$ for some lock strategy $s$, both having the pattern $G \vdash_s M \Leftarrow t$. Based on this observation the problem could be reduced to given an expression $M$ with type $t$, find the minimum set of constants $S_0 \subseteq C$ unfolded such that $G \vdash_{s(C')} M \Leftarrow t$ for an arbitrary $C' \subseteq C$ if and only if $C_0 \subseteq C'$. Also notice that with the assumption of the existence of $C_0$ there is always a simple but inefficient method to find it: we run the type checking algorithm on all the subsets of $C$ incrementally by the order of the number of elements each subset contains, and we choose the one with the minimum number of elements where the type checking process succeeds. Since the worst-case time complexity is exponential to the number of constants from $G$, we aim to find a more efficient method to this problem.

The algorithm presented below consists of a collection of auxiliary functions that are similar with the ones used in the type checking process. The idea is to discover cases where a constant must be unfolded according to the inference rules of the type checking algorithm. It resembles the type checking algorithm in many aspects but with three major differences:
\begin{enumerate}
\item Instead using two stack structures, a type checking context and an environment, to keep types and values of expressions, this algorithm uses only one context called \emph{constant searching context} that keeps both the types and values of expressions during the searching process.
\item Instead of halting with an exception when encounters a locked constant that needs to be unfolded, this algorithm queries the definition of the constant from the \emph{constant searching context} and performs a pattern match on it. 
\item Expressions are not evaluated in the context, they serve the only purpose for the case analysis operations on their patterns.
\end{enumerate}
Functions used by the algorithm are summarized in table \ref{theory:tab:summary} and their definitions are given in a Haskell-style pseudo-code in listing \ref{theory:alg:minimum}. The word ``context'' used in the following discussion refers particularly to the \emph{constant searching context}.

\begin{table}[h] 
  \centering
  \begin{tabular}{l p{10cm}}
    matchType$(G, M, T)$: & In context $G$, find the constants that need to be unlocked for the possibility that an expression $M$ has another expression $T$ as its  type. \\
    inferType($G, i, K, V$): & In context $G$, infer the type of an application $K\,V$. Because $K$ has the form either a variable $k$ or an application $K'\,V'$, the second argument indicates the direction of the recursion: 0 means doing the recursion towards the variable $k$; 1 means exiting previous recursions after having found the variable $k$. \\
    searchCon$(G, M, N, s)$: & In context $G$, given two expressions $M,N$, find the constants to be unlocked for the possibility that $M$ and $N$ are convertible. $s$ is the list of constants already found to be locked. \\
    searchFun$(G, K, V, s)$: & In context $G$, given two expressions $K,V$, find the constants to be unlocked for the possibility that $K$ is a function. $V$ is the argument to the function represented by $K$. \\
    head\_v($K$):&  Given an expression $K \in \mathcal{K}$, find the left most variable. \\
    fresh\_v$(G, x)$: & Given the name of a variable $x$, generates a new variable that does not exist in $G$. \\
    v\_val$(G, x)$:& Get the value of variable $x$ in the context $G$. \\
    v\_type$(G, x)$:& Get the type of variable $x$ in the context $G$. \\
    merge($G1, G2, M$): & Given two contexts $G1,G2$, merge the context $G2$ to $G1$ by renaming variables in $G2$ that cause name collision with that of $G1$ using the function \emph{fresh\_v}. Variables renamed in $G2$ are also renamed in the same way in $M$.
  \end{tabular}
  \caption{Summary of Functions Used to Find The Minimum Set of Constants}
  \label{theory:tab:summary}
\end{table}

\begin{lstlisting}[language=Haskell, caption={Approximation Algorithm For Minimum Set of Constants}, label={theory:alg:minimum}]
{-|
* @param 1: the constant searching context that
  relates variables to their type and values
* @param 2: an expression M
* @param 3: an expression N
* @param 4: a list of names which represents
*           the constants already discovered

* this function searches for the constants that must be unfolded
* for the possibility that M has type N by the rules
* described in section (* \ref{theory:subsec:checkT} *).
-}
matchType :: Cont -> Exp -> Exp -> [String] -> [String]
matchType G (D M) T s = matchType (G,D) M T s
------------------------------------------------------------
matchType G U U s = s 
matchType G x U s = 
  let T = v_type G x
  in searchCon G U T s
matchType G (K V) U s =
  let (G', T) = inferType G r 0 K V
  in searchCon G' U T s 
matchType G [x:A]B U s =
  let s1 = matchType G A U s
  in matchType (G, x : A) B U s1
------------------------------------------------------------
matchType G U x s = 
  let X = v_val G x
  in searchCon G U X s
matchType G x x' s =
  let T = v_type G x 
  in searchCon G T x' s
matchType G (K V) x s = 
  let (G', T) = inferType G 0 K V
  in searchCon G' T x s
matchType G [x:A]B x' s =
  let X' = v_val G x'
  in if X' == x'
     then error 
     else x' : matchType G [x:A]B X' s
------------------------------------------------------------
matchType G U (K V) s = 
  let (G', V', s') = searchFun G K V s
  in searchCon G' U V' s'
matchType G x (K V) s = 
  let T = v_type G x 
  in searchCon G T (K V) s
matchType G (K1 V1) (K2 V2) s =
  let (G', T) = inferType G 0 K1 V1
  in searchCon G' T (K2 V2) s
matchType G [x:A]B (K V) s = 
  let (G', V', s') = searchFun G K V s
  in matchType G' [x:A]B V' s'
------------------------------------------------------------
matchType _ U [x:A]B _ = error
matchType G x [x:A]B s = 
  let T = v_type G x 
  in searchCon G T [x:A]B s
matchType G (K V) [x:A]B s = 
  let (G', T) = inferType G 0 K V
  in searchCon G' T [x:A]B s
matchType G [x:A]B [x':A']B' s =
  let s1 = matchType G A U s
      s2 = searchCon G A A' s1
  in matchType (G, x : A, x':A'=x) B B' s2

inferType :: Cont -> Int -> Exp -> Exp -> (Cont, Exp)
inferType _ _ U _ = error
inferType G 0 x V =
  let T = v_type G x
  in inferType G 1 T V
inferType G 1 x V = (G, x V) 
inferType G 0 (K V) V' = 
  let (G', K') = inferType G 0 K V
  in case K' of
       U       -> error
       [x:A]B  -> ((G', x : A = V'), B) 
       _       -> (G', K' V')
inferType G 1 (K V) V' = (G, (K V) V')
inferType _ 0 [x:A]B _ = error  -- not beta-normal form
inferType G 1 [x:A]B V = ((G, x : A = V), B)
inferType _ 0 (D M)  _ = error  -- not allowed in syntax
inferType G 1 (D M) V = inferType (G, D) 1 M V

{-|
* @param 1: the constant searching context that
  relates variables to their type and values
* @param 2: an expression
* @param 3: an expression
* @param 4: a list of names which represents
*           the constants already discovered

* this function searches for the constants that must be unfolded
* for the possibility that m (the evaluated form of M) and n
* (the evaluated form of N) are convertible by the rules 
* described in table (* \ref{theory:tab:check-convert} *).
-}
searchCon :: Cont -> Exp -> Exp -> [String] -> [String]
searchCon G M [D]M' s = searchCon (G,D) M M' s
------------------------------------------
searchCon G U U s = s
searchCon G U x s =  
  let X = v_val G x
  in if X == x
     then error
     else searchCon G U X (s ++ [x]) 
searchCon G U (K V) s = 
  let (G', V', s') = searchFun G K V s
  in searchCon G' U V' s'
searchCon _ U [x:A]B _ = error
-------------------------------------------
searchCon G x U s = searchCon G U x s
searchCon G x x' s = 
  if x == x'
  then s
  else let X  = v_val G x
           X' = v_val G x' 
       in if X == x && X' == x'
          then error
          else if X /= x && X' /= x' -- @open condition
               then s
               else if X /= x
                    -- only x can be unfolded
                    then searchCon G X x' (s ++ [x])
                    else searchCon G x X' (s ++ [x'])
searchCon G x (K V) s = 
  let k' = head_v K
      X  = v_val G x
      K' = v_val G k'
  in if X == x && K' == k'
     then error
     else if X /= x && K' /= k' -- @open condition
          then s
          else if X /= x 
               then searchCon G X (K V) (s ++ [x])
               else let (G', V', s') = searchFun G K V s
                    in searchCon G' x V' s'
searchCon G x [z:A]M s =
  let X = v_val G x
  in if X == x then error
     else searchCon G X [z:A]M (s ++ [x])
------------------------------------------
searchCon G (K V) U s = searchCon G U (K V) s
searchCon G (K V) x s = searchCon G x (K V) s
searchCon G (K1 V1) (K2 V2) s =
  if K1 == K2
  then let (_, M1, _) = searchFun G K1 V1 s
           (_, M2, _) = searchFun G K2 V2 s
       in if M1 == M2 then s
       else searchCon G V1 V2 s
  else let (G1, M1, s1) = searchFun G K1 V1 s
           (G2, M2, s2) = searchFun G K2 V2 s 
       in if M1 == M2 then s1 ++ s2
       else let (G', M2') = merge(G1, G2, M2)
            in searchCon G' M1 M2' (s1 ++ s2)
searchCon G (K V) [x:A]B s =
  let (G', V', s') = searchFun G K V s
  in searchCon G' V' [x:A]B s'
------------------------------------------
searchCon G [x:A]B U s = error
searchCon G [x:A]B y s = searchCon G y [x:A]B x
searchCon G [x:A]B (K V) s = searchCon G (K V) [x:A]B s
searchCon G [x:A]B [x':A']B's =
  let s' = searchCon G A A' s
      y  = fresh_v G x
      G' = (G, x : A = y, x' : A' = y)
  in searchCon G' B B' s'

{-|
* @param 1: constant searching context that relates
  variables to their types and values 
* @param 2: expression which is checked to represent a function
* @param 3: expression which is applied to the function represented
*           by @param 2
* @param 4: a list of names which represents the constants already
*           discovered
* @return:  1. a new constant searching context where variables
*              bound by the lambdas are bound to expression at
*              @param 3 in the constant searching context
*           2. function body after the lambda abstraction
*              being eliminated
*           3. the accumulated list of constants found
*              to be unlocked
*
* this function searches for the constants that must be unfolded
* for the possibility that the expression as the second
* argument is a function.
-}
searchFun :: Cont -> Exp -> Exp -> [String] -> (Cont, Exp, [String])
searchFun _ U _ _ = error
searchFun G x V s =
  let X = v_val G x
  in if X == x then error else searchFun G X V (s ++ [x]) 
searchFun G (K V) V' s =
  let (G', K', s') = searchFun G K V s
  in searchFun G' K' V' s'
searchFun G [x:A]B V s = ((G, x : A = V), B, s)

-- Given an constant searching context and a name, generates a new
-- variable that does not in the constant searching context  
fresh_v :: Cont -> String -> String 
fresh_v G x = if x not in G then x else x''

-- @param 1: an expression of K
-- Get the head variable of @param 1
head_v :: Exp -> Exp
head_v x      = x
head_v (K _)  = head_v K
head_v _      = error

-- @param 1: the constant searching context
-- @param 2: the name of a variable
-- Get the expression bound to the variable with
-- name @param 2 in context @param 1
v_val :: Cont -> String -> Exp
v_val (G, x' : A) x =
  if x' == x then x else v_val G x
v_val (G, x' : A = B) x = 
  if x' == x then B else v_val G x

-- @param 1: the constant searching context
-- @param 2: the name of a variable
-- Get the type bound to the variable with
-- name @param 2 in context @param 1
v_type :: Cont -> String -> Exp
v_type (G, x' : A ) x    =
  if x' == x then A else v_type G x
v_type (G, x' : A = B) x = 
  if x' == x then A else v_type G x

-- @param 1: context G1
-- @param 2: context G2
-- @param 3: an expression M
-- Merge G2 into G1 by renaming variables in G2
-- that name collides with that in G1.
-- Variables renamed in G2 are also renamed in
-- expression M for the purpose of mapping
merge :: Cont -> Cont -> Exp -> (Cont, Exp)
merge G1 G2 M =
  for each declaration d in G2:
    case d of
      x : A -> if x in G1 
               then let x' = fresh_v(G1,x)
                        M' = rename(x, x', M)
                    in ((G1, x' : A), M')
               else ((G1, x : A), M)
      x : A = B ->              
        if x in G1
        then let x' = fresh_v(G1, x)
                 M' = rename(x, x', M)
             in ((G1, x' : A = B), M')
        else ((G1, x : A = B), M)
  return the final result (G', M')

-- @param 1: name x1
-- @param 2: name x2
-- @param 3: an expression M
-- rename each free occurrence of variable x1 in M to x2
-- definition is ignored
rename :: String -> String -> Exp -> Exp
\end{lstlisting}

The algorithm presented above is only an approximation because of the \emph{open conditions} marked by the comments in the pseudo-code, such as when checking the convertibility of two constants $x,x'$ with different names but both having definitions. In cases like this, it is not clear which one should be unfolded to get a minimum set. Errors marked in the algorithm only occur when expression $M$ does not have type $t$ in terms of checking the formula $G \vdash_s M \Leftarrow t$. The \emph{constant searching context} is basically the same with a type checking context except that we use it to hold both values and types of bound variables in function abstractions. Lastly, to use the function \emph{matchType} on two expressions, we need to apply an operation called \emph{readBack} to turn the q-expression $t$ in the formula to an expression, which will be described in the following section.

\subsection{Linear Head Reduction}\label{theory:head-red}
\emph{Linear Head reduction} was introduced in the calculus $\Delta\Lambda$ of AUTOMATH\cite{de1994generalizing} and is demonstrated here as to show another way to limit computation. It forces expressions to be evaluated in ``small steps'' once a time instead of being fully evaluated. It features with a procedure where closures are eliminated so that the result of head reduction is an expression instead of a quasi-expression. We denote this function as $\delta$ and give its definition in table \ref{theory:tab:head-red}.
\begin{table}[h]
  \centering
  \begin{tabular}{l l p{8cm}}
    $\delta(\Gamma, U)$ & = & $U$ \\
    $\delta(\Gamma, [x : A]M)$ & = & let $M' = \delta((\Gamma, x:A), M)$ in $[x : A]M'$\\
    $\delta(\Gamma, D\,M)$ & = & let $M' = \delta((\Gamma, D), M)$ in $D\,M'$\\
    $\delta(\Gamma, K)$ & = & $\mathcal{R}_{\tau(\Gamma)}(\delta^*(\Gamma, K))$
  \end{tabular}
  \caption{Function - Head Reduction}
  \label{theory:tab:head-red}
\end{table}

The procedure to eliminate closures is achieved by a function called \emph{readBack} which is denoted by $\mathcal{R}$. Given a list of names and a q-expression, it eliminates all the closures in the q-expression to transform it into an expression. The definition of \emph{readBack} is given in table \ref{theory:tab:readBack}.
\begin{table}[h] 
  \centering
  \begin{tabular}{l l p{8cm}}
    $\mathcal{R}(\_, U)$ & = & U \\
    $\mathcal{R}(\_, x)$ & = & x \\
    $\mathcal{R}(ns, k\,v)$ & = & let $K = \mathcal{R}(ns, k)$, $N = \mathcal{R}(ns, v)$ in $K\,N$ \\
    $\mathcal{R}(ns, \langle [x : A] B, \rho \rangle))$ & = & let $y = \nu(ns, x)$, $A' = \mathcal{R}(ns, A_\rho)$, $B' = \mathcal{R}(y:ns, B_{(\rho, x=y)})$ in $[y : A'] B'$.
  \end{tabular}
  \caption{Function: readBack}
  \label{theory:tab:readBack}
\end{table}

For expressions in forms of $K$, an auxiliary function is used to head reduce this expression to a q-expression. We call this function \emph{headRedV} and denote it as $\delta^*$. The definition of \emph{headRedV} is given in table \ref{theory:tab:headRedV}.
\begin{table}[h]
  \centering
  \begin{tabular}{l l p{8cm}}
    $\delta^*(\Gamma, x)$ & = & $\mathcal{V}(\Gamma, x)$ \\
    $\delta^*(\Gamma, K\,N)$ & = & let $k = \delta^*(\Gamma, M)$, $n = N_{()}$ in $app(k,n)$
  \end{tabular}
  \caption{Function - HeadRedV}
  \label{theory:tab:headRedV}
\end{table}

The empty parentheses represents an empty environment. $\mathcal{V}(\Gamma, x)$ is a function to get the least evaluated form of variable $x$ from context $\Gamma$. We call it \emph{getVal} and give its definition in table \ref{theory:tab:getVal}. Note that to reduce an application $K\,N$, our approach is different with what is adopted by a Krivine machine\footnote{visit this \href{https://en.wikipedia.org/wiki/Krivine_machine}{website} from wikipedia for an introduction.}: instead of evaluating both the body and argument of a function within a given environment $\rho$ (i.e., ($K_\rho\,N_\rho$)), we only unfold the body but do not distribute the environment to the argument. 
\begin{table}[h]
  \centering
  \begin{tabular}{l l l}
    $\mathcal{V}((), x)$ & = & $x$ \\
    $\mathcal{V}((\Gamma', x' : A), x)$ & = & if $x' == x$ then $x$ else $\mathcal{V}(\Gamma', x)$ \\
    $\mathcal{V}((\Gamma', x' : A = B), x)$ & = & if $x' == x$ then $B_{()}$ else $\mathcal{V}(\Gamma', x)$
  \end{tabular}
  \caption{Function - getVal}
  \label{theory:tab:getVal}
\end{table}

As an example of head reduction, we apply this function continuously, first on a constant named ``loop'' from a source file of our language, later on the expression resulting from the last application, to see how the evaluation on the constant ``loop'' evolves. The source file is a variation of the Hurkens paradox\cite{hurkens1995simplification} and is given in appendix \ref{apdix:loop}. The result of the first ten steps of head reduction are shown in appendix \ref{apdix:hred} and one can see that there are patterns of terms recurring and replicating themselves as the evaluation goes further.
